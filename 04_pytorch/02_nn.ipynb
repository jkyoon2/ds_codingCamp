{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbU-HSp7lIKZ"
      },
      "source": [
        "## <span style=\"color:#FFC1C1; font-weight:bold\">2. nn.Module</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcjjuNHJlIKd"
      },
      "source": [
        "####  ì‹ ê²½ë§ êµ¬ì„±\n",
        "\n",
        "- ë ˆì´ì–´(layer): ì‹ ê²½ë§ì˜ í•µì‹¬ ë°ì´í„° êµ¬ì¡°ë¡œ í•˜ë‚˜ ì´ìƒì˜ í…ì„œë¥¼ ì…ë ¥ë°›ì•„ í•˜ë‚˜ ì´ìƒì˜ í…ì„œë¥¼ ì¶œë ¥\n",
        "- ëª¨ë“ˆ(module): í•œ ê°œ ì´ìƒì˜ ê³„ì¸µì´ ëª¨ì—¬ì„œ êµ¬ì„±\n",
        "- ëª¨ë¸(model): í•œ ê°œ ì´ìƒì˜ ëª¨ë“ˆì´ ëª¨ì—¬ì„œ êµ¬ì„±"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6hmgLsylIKg"
      },
      "source": [
        "#### `torch.nn` íŒ¨í‚¤ì§€\n",
        "\n",
        "ì£¼ë¡œ ê°€ì¤‘ì¹˜(weights), í¸í–¥(bias)ê°’ë“¤ì´ ë‚´ë¶€ì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ë ˆì´ì–´ë“¤ì„ ì‚¬ìš©í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤! (`weight`ê°’ë“¤ì„ ì§ì ‘ ì„ ì–¸ ì•ˆí•¨)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1hNCXrNlIKi"
      },
      "source": [
        "1. `nn.Linear` ê³„ì¸µ ì˜ˆì œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tHPokdNWlIKj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx4sd8jGlIKm",
        "outputId": "a6bc4bd3-d6b2-40f0-8c07-ada2bffb770b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.0676, -0.0989, -0.0670,  ...,  0.8140,  0.7822, -1.2714],\n",
            "        [ 0.7406, -0.0217, -1.1408,  ...,  0.5388,  1.3454, -0.6178],\n",
            "        [ 1.8179,  0.3228,  0.2990,  ..., -0.4869, -0.1050,  1.1327],\n",
            "        ...,\n",
            "        [-1.1455, -0.1215, -0.1995,  ..., -1.8318, -1.3728,  0.2914],\n",
            "        [ 0.0791, -0.5305, -0.6160,  ...,  1.4103, -0.7648, -0.9064],\n",
            "        [ 0.5358,  0.0339,  0.1657,  ...,  2.8516,  1.4224, -1.0641]])\n",
            "Linear(in_features=20, out_features=30, bias=True)\n",
            "tensor([[ 4.0962e-01, -1.2111e-02,  4.3441e-01,  ...,  5.6932e-01,\n",
            "          4.8634e-01, -8.9426e-05],\n",
            "        [ 6.1350e-01,  1.2618e+00,  2.8604e-02,  ..., -1.6180e-01,\n",
            "         -4.6309e-02, -3.4037e-01],\n",
            "        [-1.3091e-01, -4.3149e-01, -2.3915e-02,  ..., -4.7574e-01,\n",
            "          7.4747e-01, -3.1817e-02],\n",
            "        ...,\n",
            "        [ 3.0377e-01, -1.9558e-01,  6.9033e-01,  ...,  4.5507e-01,\n",
            "          3.8493e-01,  7.3751e-01],\n",
            "        [ 5.1184e-01, -7.9964e-01,  4.6262e-02,  ...,  2.8012e-01,\n",
            "          5.9790e-01, -7.9323e-01],\n",
            "        [ 6.1534e-01,  3.2582e-01, -3.4197e-01,  ..., -1.0513e+00,\n",
            "         -2.5221e-01, -4.6031e-01]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([128, 30])\n"
          ]
        }
      ],
      "source": [
        "input = torch.randn(128, 20)\n",
        "print(input)\n",
        "\n",
        "m = nn.Linear(20, 30)\n",
        "print(m)\n",
        "\n",
        "output = m(input)\n",
        "print(output)\n",
        "print(output.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCGGtRVFlIKo"
      },
      "source": [
        "2. `nn.Conv2d` ê³„ì¸µ ì˜ˆì œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVDZ1G4flIKq",
        "outputId": "f007d2c3-5cae-41cb-9495-1af62d6b2935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20, 16, 50, 100])\n"
          ]
        }
      ],
      "source": [
        "input = torch.randn(20, 16, 50, 100)\n",
        "print(input.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q7cE9g_olIKt"
      },
      "outputs": [],
      "source": [
        "m = nn.Conv2d(16, 33, 3, stride=2)\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2,1), padding=(4,2))\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2,1), padding=(4,2), dilation=(3,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4NJZ2bQlIKu",
        "outputId": "6e666ae6-5336-42ff-bba5-e6ee2a79bd50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20, 33, 26, 100])\n"
          ]
        }
      ],
      "source": [
        "output = m(input)\n",
        "print(output.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nkcoH9xlIKw"
      },
      "source": [
        "#### `nn.Module` ìƒì† í´ë˜ìŠ¤ ì •ì˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzPOm2jklIKx"
      },
      "source": [
        "nn.Moduleì€ <span style=\"color:#FFC1C1; font-weight:bold\">PyTorchì˜ ëª¨ë“  Neural Networkì˜ Base Class</span>ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ ì‹ ê²½ë§ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆì£ !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kXpPHf3SlIKy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX-yIXEflIKz"
      },
      "source": [
        "### ê¸°ë³¸ method  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4NOMOgGlIKz"
      },
      "source": [
        "ê°„ë‹¨í•˜ê²Œ nn.Moduleì„ ìƒì†í•œ Add í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤!\n",
        "\n",
        "í´ë˜ìŠ¤ ë‚´ì—ì„œ 2ê°€ì§€ë¥¼ ë°˜ë“œì‹œ ì •ì˜í•´ì¤˜ì•¼í•©ë‹ˆë‹¤\n",
        "- `__init__()`: ëª¨ë¸ì—ì„œ ì‚¬ìš©ë  ëª¨ë“ˆê³¼ í™œì„±í™” í•¨ìˆ˜ ë“±ì„ ì •ì˜\n",
        "- `forward()`: ëª¨ë¸ì—ì„œ ì‹¤í–‰ë˜ì–´ì•¼ í•˜ëŠ” ì—°ì‚°ì„ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ftFv6jBplIK0"
      },
      "outputs": [],
      "source": [
        "class Add(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # ë°˜ë“œì‹œ Add classì˜ ë¶€ëª¨ í´ë˜ìŠ¤ì¸ nn.Moduleì„ super()ì„ ì‚¬ìš©í•´ì„œ ì´ˆê¸°í™” ì‹œì¼œì¤˜ì•¼ í•œë‹¤.\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = torch.add(x1, x2)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Lt4rt02PlIK0"
      },
      "outputs": [],
      "source": [
        "x1 = torch.tensor([1])\n",
        "x2 = torch.tensor([2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hIvgoMHRlIK1"
      },
      "outputs": [],
      "source": [
        "model = Add()\n",
        "output = model(x1, x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgZPMJNnlIK2",
        "outputId": "cd626fd6-1e16-499e-f518-ee31a686a5f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3])\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hlno3zslIK2"
      },
      "source": [
        "ì—‡... ê·¸ëŸ°ë° ìš°ë¦¬ê°€ í”íˆ ì•Œê³  ìˆëŠ” í´ë˜ìŠ¤ì—ì„œ í•¨ìˆ˜ ì‚¬ìš©ë²•ì´ë‘ ë‹¤ë¥¸ê±° ëˆˆì¹˜ì±˜ë‚˜ìš”?\n",
        "\n",
        "model.forward()ì™€ ê°™ì´ í˜¸ì¶œí•˜ì§€ ì•Šì•˜ëŠ”ë° ë‹¨ìˆœíˆ model ê°ì²´ë¥¼ ë°ì´í„°ì™€ í•¨ê»˜ í˜¸ì¶œí•˜ë©´ ìë™ìœ¼ë¡œ forward() í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ì—ˆì–ì•„ìš”.\n",
        "\n",
        "ì™œ ì´ëŸ° ì¼ì´ ë°œìƒí•˜ëŠ”ì§€ ì´í•´í•˜ê¸° ìœ„í•´ì„œ `nn.Module`ì˜ ì†ŒìŠ¤ì½”ë“œë¥¼ ëœ¯ì–´ë´ì•¼í•©ë‹ˆë‹¤!\n",
        "\n",
        "https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/module.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2htndNvzlIK3"
      },
      "source": [
        "ê·¸ë¦¬ê³  ì´ë¥¼ ì´í•´í•˜ê¸° ì „ì— `__call__`ì´ë€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ì§šê³  ë„˜ì–´ê°ˆê²Œìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idJMwd2jlIK3"
      },
      "source": [
        "- `__call__` : í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§ˆì¹˜ í•¨ìˆ˜ì²˜ëŸ¼ í˜¸ì¶œí•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë©”ì†Œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kvu-6az4lIK4"
      },
      "outputs": [],
      "source": [
        "class Plus:\n",
        "\n",
        "\tdef add(self, n1, n2):\n",
        "\t\treturn n1 + n2\n",
        "\n",
        "\t__call__ = add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84PeVo66lIK4",
        "outputId": "17c990af-bafe-4991-ab4d-80bb5cec605f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "myinstance = Plus()\n",
        "myinstance(1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyu1ormelIK5"
      },
      "source": [
        "ì¦‰, `__call__`ê°€ `add` ë©”ì†Œë“œë¥¼ ê°€ë¦¬í‚¤ê³  ìˆì–´ì„œ, Plusì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•¨ìˆ˜ì²˜ëŸ¼ í˜¸ì¶œí–ˆì„ë•Œ add ë©”ì†Œë“œê°€ ì‹¤í–‰ë˜ëŠ”ê±°ì—ìš”!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i9NEcBylIK5"
      },
      "source": [
        "ê·¸ë ‡ë‹¤ë©´ `nn.Module`ì˜ ì†ŒìŠ¤ì½”ë“œ ìƒ `__call__`ì€ ë¬´ì—‡ì„ ì–´ë–¤ ë©”ì†Œë“œë¥¼ ê°€ë¦¬í‚¤ê³  ìˆì„ê¹Œìš”? (1634ë²ˆì§¸ ì¤„)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaGB2KA7lIK6"
      },
      "source": [
        "![__call__ë©”ì†Œë“œ](https://github.com/jkyoon2/ds_codingCamp/blob/main/04_pytorch/image/__call__.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sLBeuQHlIK6"
      },
      "source": [
        "`_wrapped_call_impl`ì„ ê°€ë¦¬í‚¤ê³  ìˆêµ°ìš”. (1507ë²ˆì§¸ ì¤„)\n",
        "\n",
        "`_wrapped_call_impl`ì€ ë¬´ì—‡ì„ ê°€ë¦¬í‚¬ê¹Œìš”?\n",
        "\n",
        "![_wrapped_call_impl](https://github.com/jkyoon2/ds_codingCamp/blob/main/04_pytorch/image/_wrapped_call_impl.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "073o9eDzlIK7"
      },
      "source": [
        "`_call_impl`ì„ ê°€ë¦¬í‚¤ê³  ìˆêµ°ìš”. (1513ë²ˆì§¸ ì¤„)\n",
        "\n",
        "`_call_impl`ì€ ë³µì¡í•œ error handling ì½”ë“œë¥¼ ê°€ì§€ê³  ìˆì§€ë§Œ, ë¬¸ì œê°€ ì—†ë‹¤ë©´ `forward`ì„ í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoKiefTPlIK7"
      },
      "source": [
        "![_call_impl](https://github.com/jkyoon2/ds_codingCamp/blob/main/04_pytorch/image/_call_impl.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsr9tbIAlIK8"
      },
      "source": [
        "ì¦‰, ìš°ë¦¬ê°€ ì˜¤ë²„ë¼ì´ë”©í•œ forward() ë©”ì†Œë“œëŠ” í´ë˜ìŠ¤ë¥¼ ì¸ìŠ¤í„´ìŠ¤ í•œ í›„, inputë§Œ ë„£ì–´ì£¼ë©´ ì‹¤í–‰ë˜ëŠ” ê²ƒì´ì£ !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sea1hYnlIK9"
      },
      "source": [
        "ì—¬ê¸°ê¹Œì§€ ì™”ë‹¤ë©´, ë‹¤ëœê²ƒê³¼ ë‹¤ë¦„ ì—†ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ì œ ì¶”ê°€ì ìœ¼ë¡œ ë§ì´ ì“°ì´ëŠ” í•¨ìˆ˜ë“¤ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j31ps1RrlIK-"
      },
      "source": [
        "### ì¶”ê°€ì  method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXcZmFa2lILA"
      },
      "source": [
        "1. `apply`\n",
        "\n",
        "- ëª¨ë“  submoduleì— í•¨ìˆ˜ë¥¼ ì ìš©í•˜ëŠ” ì—­í• "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVSbPNi1lILA"
      },
      "source": [
        "ì ê¹! submoduleì„ ì§šê³  ë„˜ì–´ê°ˆê²Œìš”.  \n",
        "\n",
        "ìš°ì„ , ëª¨ë“ˆì€ ë‹¤ë¥¸ ëª¨ë“ˆì„ í¬í•¨í•  ìˆ˜ ìˆê³ , íŠ¸ë¦¬ êµ¬ì¡°ë¡œ í˜•ì„±ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, nn.Sequential ì•ˆì—ëŠ” nn.Linear, nn.Conv2d í¬í•¨ë  ìˆ˜ ìˆê² ì£ .\n",
        "\n",
        "ì´ë•Œ, ëª¨ë¸ ë‚´ì˜ ëª¨ë“  nn.Moduleì„ ìƒì† ë°›ëŠ” í´ë˜ìŠ¤ëŠ” submoduleì…ë‹ˆë‹¤.\n",
        "\n",
        "applyëŠ” ëª¨ë“  submoduleì— ì¬ê·€ì (recursive)ìœ¼ë¡œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•  ë•Œ ëª¨ë¸ì— ì‚¬ìš©í•˜ë©´, ëª¨ë“  íŠ¸ë¦¬êµ¬ì¡°ì˜ submoduleë“¤ì— ì¼ê´„ ì ìš©í•  ìˆ˜ ìˆê² ì£ ~?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hmFqzb9zlILB"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def init_weights(m):\n",
        "     print(m)\n",
        "     if type(m) == nn.Linear:   # ëª¨ë¸ì˜ ëª¨ë“  submoduleì— ëŒ€í•´ nn.Linearê°€ ìˆìœ¼ë©´ ì•„ë˜ë¥¼ ìˆ˜í–‰\n",
        "         m.weight.fill_(1.0)    # fill_(1.0)ì€ fillì˜ in-place operationìœ¼ë¡œ, nn.Linearì˜ weightë¥¼ ëª¨ë‘ 1.0ìœ¼ë¡œ ì±„ìš´ë‹¤ëŠ” ëœ»\n",
        "         print(m.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQSPcO9dlILB",
        "outputId": "9733a719-bc8c-4fbf-f7e6-f5aeea3b3609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=2, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "Linear(in_features=2, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
            "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
        "net.apply(init_weights)                    # apply(fn) ì ìš© ë°©ë²•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGGzBoo3lILC"
      },
      "source": [
        "2. `cpu`, `cuda`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S0ghvmGlILC"
      },
      "source": [
        "- ëª¨ë¸ì„ ì–´ëŠ ë””ë°”ì´ìŠ¤ì— ì˜¬ë¦´ ê²ƒì¸ì§€ ê²°ì •\n",
        "- ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë¸ì€ CPUì— ì˜¬ë¼ê°€ ìˆìŒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uBsVP97Uo5pA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAnl7uqJlWzj",
        "outputId": "bc8029d1-0044-49b1-f22b-7ab38d470076"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()  # Trueì¸ ê²½ìš° GPU, ì¦‰ cudaë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ëœ»(cudaëŠ” gpuë¡œ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” í”„ë¡œê·¸ë¨)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWUFVYienT9M",
        "outputId": "38a88e72-b128-4f75-b8e7-45e0ace854bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhFwZcR2rQCj"
      },
      "source": [
        "ë°ì´í„°ê°€ í´ìˆ˜ë¡, ë§ì„ìˆ˜ë¡ cudaë¥¼ ì‚¬ìš©í•˜ë©´ ì‹œê°„ì„ ë§ì´ ì•„ë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.ğŸ˜\n",
        "\n",
        "modelì„ cudaì— ì˜¬ë¦¬ëŠ” ë°©ë²•ìœ¼ë¡œëŠ” ì•„ë˜ì™€ ê°™ì´ '**to(device)**'ë¥¼ ë¶™ì´ë©´ ë©ë‹ˆë‹¤. cudaë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒí™©ì—ì„œëŠ” cudaì—ì„œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ cpuë¥¼ í™œìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ë•Œ, ìœ„ì™€ ê°™ì´ deviceë¥¼ ê¼­ ë¨¼ì € ì •ì˜í•´ì£¼ì–´ì•¼í•©ë‹ˆë‹¤.\n",
        "\n",
        "[ì˜ˆì‹œ] clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").**to(device)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRIqdBvmlILO"
      },
      "source": [
        "3. `parameters`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s_NKkjclILO"
      },
      "source": [
        "- ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ë‹´ì€ iteratorë¥¼ return\n",
        "- ë³´í†µ optimizer ì„ ì–¸í•  ì‹œ argumentë¡œ ë„£ì–´ì¤Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amQIeqqBlILP"
      },
      "outputs": [],
      "source": [
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhYWxBoAlILP"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrrRky6dlILQ"
      },
      "source": [
        "4. `state_dict`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_V-IIHElILR"
      },
      "source": [
        "- ëª¨ë¸ì˜ submoduleì„ dictionary í˜•íƒœë¡œ ë°˜í™˜\n",
        "- ëª¨ë¸ ì €ì¥/ë¡œë“œí•  ë•Œ ì”€\n",
        "\n",
        "ì•„ë˜ëŠ” íŒŒì´í† ì¹˜ ê³µì‹ ë¬¸ì„œì— ë‚˜ì™€ìˆëŠ” ì˜ˆì‹œ ì½”ë“œì…ë‹ˆë‹¤.\n",
        "\n",
        "ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ì„¸ì„¸íˆ ì´í•´í•˜ë ¤ê³  í•˜ê¸°ë³´ë‹¨ ìš°ì„  state_dictì— ì–´ë–¤ ê°’ë“¤ì´ ì €ì¥ë˜ëŠ”ì§€ ì‚´í´ë´…ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge5ASMbltNm2",
        "outputId": "0830bd13-d193-41a7-ad4e-5324bd6e2afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model's state_dict:\n",
            "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
            "conv1.bias \t torch.Size([6])\n",
            "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
            "conv2.bias \t torch.Size([16])\n",
            "fc1.weight \t torch.Size([120, 400])\n",
            "fc1.bias \t torch.Size([120])\n",
            "fc2.weight \t torch.Size([84, 120])\n",
            "fc2.bias \t torch.Size([84])\n",
            "fc3.weight \t torch.Size([10, 84])\n",
            "fc3.bias \t torch.Size([10])\n",
            "Optimizer's state_dict:\n",
            "state \t {}\n",
            "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "# ëª¨ë¸ ì •ì˜\n",
        "class TheModelClass(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TheModelClass, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "model = TheModelClass()\n",
        "\n",
        "# ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# ëª¨ë¸ì˜ state_dict ì¶œë ¥\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# ì˜µí‹°ë§ˆì´ì €ì˜ state_dict ì¶œë ¥\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uXjdk3jLuCe9"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'full_model.pt')            # 1ë²ˆ\n",
        "torch.save(model.state_dict(), 'model.pt')    # 2ë²ˆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_YBYLJNumzA"
      },
      "source": [
        "**[ëª¨ë¸ ì „ì²´ë¥¼ ì €ì¥í•˜ëŠ” 1ë²ˆ ì½”ë“œ]**\n",
        "\n",
        "\n",
        "*   íŒŒë¼ë¯¸í„°, ì—í¬í¬ ë“± ëª¨ë“  ì •ë³´ ì €ì¥\n",
        "*   ë‚˜ì¤‘ì— í•™ìŠµì„ ì´ì–´ì„œ í•˜ê³  ì‹¶ì„ ë•Œ\n",
        "*   ë” í° ìš©ëŸ‰ í•„ìš”\n",
        "\n",
        "**[ëª¨ë¸ì˜ state_dictë§Œ ì €ì¥í•˜ëŠ” 2ë²ˆ ì½”ë“œ]**\n",
        "\n",
        "\n",
        "*   ê°€ì¤‘ì¹˜, í¸í–¥ ë“± í•™ìŠµë˜ëŠ” ë³€ìˆ˜ì— ëŒ€í•œ ì •ë³´ ì €ì¥\n",
        "*   ì½”ë“œ ìƒ ëª¨ë¸ì´ êµ¬í˜„ë˜ì–´ ìˆì„ ë•Œë§Œ!\n",
        "*   ì‘ì€ ìš©ëŸ‰ ì‚¬ìš©\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2r0HMgqlILR"
      },
      "source": [
        "5. `train`, `eval`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXOQ43rFlILR"
      },
      "source": [
        "- ëª¨ë¸ trainì„ ì‹œì‘í•  ë•ŒëŠ” `model.train()`, evaluationì„ ì‹œì‘ í•  ë•ŒëŠ” `model.eval()`ì„ ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDdZEYlHlILS"
      },
      "source": [
        "ğŸ™‹â€â™€ï¸ <span style=\"color:#D8BFD8; font-weight:bold\"> ì´ë ‡ê²Œ trainê³¼ evaluation ì‹œì‘í• ë•Œ `train()`, `eval()` ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•˜ëŠ” ì´ìœ ê°€ ë¬´ì—‡ì¼ê¹Œìš”? </span> ğŸ™‹â€â™€ï¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVdNmSyDlILS"
      },
      "source": [
        "1. Dropoutì´ë‚˜ BatchNorm ê°™ì€ ë ˆì´ì–´ë“¤ì€ í•™ìŠµ ì‹œì™€ í‰ê°€ ì‹œì— ë‹¤ë¥´ê²Œ ë™ì‘í•˜ë„ë¡ ì„¤ê³„ë˜ì–´ ìˆëŠ”ë°ìš”, `train()`, `eval()` ë©”ì†Œë“œë¥¼ í†µí•´ ëª¨ë¸ ë‚´ í•´ë‹¹ ë ˆì´ì–´ë“¤ì„ ì¼ì¼ì´ ëª¨ë“œ ë³€ê²½í•˜ì§€ ì•Šê³  ì†ì‰½ê²Œ ì¼ê´„ ë³€ê²½ ì‹œì¼œì¤ë‹ˆë‹¤.\n",
        "\n",
        "2. ë‹¨ìˆœí•œ ëª¨ë¸ì€ outputë§Œìœ¼ë¡œ lossë¥¼ êµ¬í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. (outputê³¼ targetì„ í†µí•´ lossë¥¼ êµ¬í•œ í›„, `backward()`, `optimizer.step()`ì„ í•´ì£¼ë©´ ë˜ì£ ) í•˜ì§€ë§Œ ë³´ë‹¤ ë³µì¡í•œ ëª¨ë¸ë“¤ì€ outputë§Œìœ¼ë¡œ lossë¥¼ êµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Object detection modelì¸ detectron2ë§Œ ë´ë„ forward() ë‚´ë¶€ì— lossë¥¼ êµ¬í•˜ëŠ” ê³¼ì •ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ì‹¬ì§€ì–´ lossë„ detector_losses, proposal_lossesë¡œ 2ê°œì…ë‹ˆë‹¤. ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì‚¬ëŒ ì…ì¥ì—ì„œëŠ” ì‚¬ìš©ìê°€ lossë¥¼ ê³„ì‚°í•˜ê¸° ë„ˆë¬´ ì–´ë µì£ . ê·¸ë˜ì„œ `forward()` ë‚´ë¶€ì— Lossë¥¼ êµ¬í•˜ëŠ” ê³¼ì •ì„ ì¶”ìƒí™”í•˜ê³ , train modeì´ë©´ lossë‚˜ lossì˜ ì´í•©ì„ returní•˜ê³  inference mode(train mode = False)ì´ë©´ predictionì„ returní•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC8BaTE1lILT"
      },
      "source": [
        "ì°¸ê³ ë¥¼ ìœ„í•´ detectron2 `forward()` ë‚´ë¶€ì— êµ¬í˜„ëœ loss ë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤~\n",
        "\n",
        "![detectron2_forward()](https://github.com/jkyoon2/ds_codingCamp/blob/main/04_pytorch/image/detectron2_forward().png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5NYh8xUlILT"
      },
      "source": [
        "ê·¸ëŸ¼ ì´ì œ ëª¨ë“  ì¤€ë¹„ë¥¼ ë§ˆì¹œ ì…ˆì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ì œ ì§ì ‘... ì‚¬ê³¼ í† ë§ˆí†  ë³µìˆ­ì•„ ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤ ğŸğŸ…ğŸ‘"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
